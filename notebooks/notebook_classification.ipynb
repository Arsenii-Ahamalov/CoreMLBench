{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9761442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv('../data/WineQT_raw.csv')\n",
    "Xtrain,Xrest,ytrain,yrest = train_test_split(data.drop('quality',axis=1),data['quality'],test_size=0.4,random_state=42)\n",
    "Xval,Xtest,yval,ytest = train_test_split(Xrest,yrest,test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ee1f341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 685 entries, 1137 to 1126\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         685 non-null    float64\n",
      " 1   volatile acidity      685 non-null    float64\n",
      " 2   citric acid           685 non-null    float64\n",
      " 3   residual sugar        685 non-null    float64\n",
      " 4   chlorides             685 non-null    float64\n",
      " 5   free sulfur dioxide   685 non-null    float64\n",
      " 6   total sulfur dioxide  685 non-null    float64\n",
      " 7   density               685 non-null    float64\n",
      " 8   pH                    685 non-null    float64\n",
      " 9   sulphates             685 non-null    float64\n",
      " 10  alcohol               685 non-null    float64\n",
      " 11  Id                    685 non-null    int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 69.6 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>5.4</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.089</td>\n",
       "      <td>16.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.99402</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>11.6</td>\n",
       "      <td>1591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.065</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.99460</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>8.2</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.074</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.5</td>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>10.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99570</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.7</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.081</td>\n",
       "      <td>16.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.99564</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.60</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "1137            5.4              0.74         0.09             1.7      0.089   \n",
       "7               7.3              0.65         0.00             1.2      0.065   \n",
       "477             8.2              0.73         0.21             1.7      0.074   \n",
       "155             7.5              0.49         0.19             1.9      0.076   \n",
       "895             7.2              0.57         0.05             2.3      0.081   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "1137                 16.0                  26.0  0.99402  3.67       0.56   \n",
       "7                    15.0                  21.0  0.99460  3.39       0.47   \n",
       "477                   5.0                  13.0  0.99680  3.20       0.52   \n",
       "155                  10.0                  44.0  0.99570  3.39       0.54   \n",
       "895                  16.0                  36.0  0.99564  3.38       0.60   \n",
       "\n",
       "      alcohol    Id  \n",
       "1137     11.6  1591  \n",
       "7        10.0     7  \n",
       "477       9.5   673  \n",
       "155       9.7   218  \n",
       "895      10.3  1266  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Xtrain.info())\n",
    "display(Xtrain.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca2f11a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data : pd.DataFrame):\n",
    "    for column in data.columns:\n",
    "        if column == 'quality':\n",
    "            data[column] = data[column].fillna(data[column].mean())\n",
    "        else:   \n",
    "            data[column] = data[column].fillna(data[column].mean())\n",
    "    return data\n",
    "\n",
    "Xtrain = data_preprocessing(Xtrain)\n",
    "Xval = data_preprocessing(Xval)\n",
    "Xtest = data_preprocessing(Xtest)\n",
    "data = data_preprocessing(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5539dca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "standart_scaler = StandardScaler()\n",
    "normal_scaler = MinMaxScaler()\n",
    "\n",
    "Xtrain_standart = pd.DataFrame(standart_scaler.fit_transform(Xtrain), columns=Xtrain.columns)\n",
    "Xval_standart = pd.DataFrame(standart_scaler.transform(Xval), columns=Xval.columns)\n",
    "Xtest_standart = pd.DataFrame(standart_scaler.transform(Xtest), columns=Xtest.columns)\n",
    "\n",
    "Xtrain_normal = pd.DataFrame(normal_scaler.fit_transform(Xtrain), columns=Xtrain.columns)\n",
    "Xval_normal = pd.DataFrame(normal_scaler.transform(Xval), columns=Xval.columns)\n",
    "Xtest_normal = pd.DataFrame(normal_scaler.transform(Xtest), columns=Xtest.columns)\n",
    "\n",
    "standart_data = pd.DataFrame(standart_scaler.fit_transform(data), columns=data.columns)\n",
    "normal_data = pd.DataFrame(normal_scaler.fit_transform(data), columns=data.columns)\n",
    "\n",
    "standart_data.to_csv('../data/WineQT_standart.csv', index=False)\n",
    "normal_data.to_csv('../data/WineQT_normal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d1cb06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from src.logistic_regression import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression as sklearn_LogisticRegression\n",
    "from src.knn import KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier as sklearn_KNeighborsClassifier\n",
    "from src.tree_classifier import TreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier as sklearn_DecisionTreeClassifier\n",
    "def model_tuning(model_name,Xdata,Xvaldata,sklearn_model):\n",
    "    if model_name == 'LogisticRegression':\n",
    "        if sklearn_model == False:\n",
    "            parameters = {\n",
    "                'learning_rate': [0.001, 0.005, 0.01],\n",
    "                'n_iters': [100,200,300],\n",
    "                'fit_intercept': [True, False]\n",
    "            }\n",
    "            parameters_grid = ParameterGrid(parameters)\n",
    "            best_params = None\n",
    "            best_score = 0\n",
    "            for params in parameters_grid:\n",
    "                model = LogisticRegression(**params)\n",
    "                model.fit(Xdata,ytrain)\n",
    "                score = model.score(Xvaldata,yval)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_params = params\n",
    "            print(f\"Best score  for all variants in non-sklearn LogisticRegression: {best_score}\")\n",
    "            print(f\"Best params: {best_params}\")\n",
    "        else:\n",
    "            parameters = {\n",
    "                'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                'solver': ['lbfgs', 'newton-cg', 'sag', 'saga'],\n",
    "                'max_iter': [100,200,300]\n",
    "            }\n",
    "            parameters_grid = ParameterGrid(parameters)\n",
    "            best_params = None\n",
    "            best_score = 0\n",
    "            for params in parameters_grid:\n",
    "                model = sklearn_LogisticRegression(**params)\n",
    "                model.fit(Xdata,ytrain)\n",
    "                score = model.score(Xvaldata,yval)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_params = params\n",
    "            print(f\"Best score  for all variants in sklearn LogisticRegression: {best_score}\")\n",
    "            print(f\"Best params: {best_params}\")\n",
    "    elif model_name == 'KNN':\n",
    "        if sklearn_model == False:\n",
    "            parameters = {\n",
    "                'n_neighbors': [3, 5, 7, 9],\n",
    "                'p': [1, 2],\n",
    "                'weights': ['uniform', 'distance'],\n",
    "                'task_class': ['c']\n",
    "            }\n",
    "            parameters_grid = ParameterGrid(parameters)\n",
    "            best_params = None\n",
    "            best_score = 0\n",
    "            for params in parameters_grid:\n",
    "                model = KNN(**params)\n",
    "                model.fit(Xdata,ytrain)\n",
    "                score = model.score(Xvaldata,yval)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_params = params\n",
    "            print(f\"Best score  for all variants in non-sklearn KNN: {best_score}\")\n",
    "            print(f\"Best params: {best_params}\")\n",
    "        else:\n",
    "            parameters = {\n",
    "                'n_neighbors': [3, 5, 7, 9],\n",
    "                'p': [1, 2],\n",
    "                'weights': ['uniform', 'distance'],\n",
    "            }\n",
    "            parameters_grid = ParameterGrid(parameters)\n",
    "            best_params = None\n",
    "            best_score = 0\n",
    "            for params in parameters_grid:\n",
    "                model = sklearn_KNeighborsClassifier(**params)\n",
    "                model.fit(Xdata,ytrain)\n",
    "                score = model.score(Xvaldata,yval)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_params = params\n",
    "            print(f\"Best score  for all variants in sklearn KNN: {best_score}\")\n",
    "            print(f\"Best params: {best_params}\")\n",
    "    else:\n",
    "        if sklearn_model == False:\n",
    "            parameters = {\n",
    "                'max_depth': range(2,10),\n",
    "                'min_samples_split': [2, 3, 4,5],\n",
    "                'criterion': ['gini', 'entropy']\n",
    "            }\n",
    "            parameters_grid = ParameterGrid(parameters)\n",
    "            best_params = None\n",
    "            best_score = 0\n",
    "            for params in parameters_grid:\n",
    "                model = TreeClassifier(**params)\n",
    "                model.fit(Xdata,ytrain)\n",
    "                score = model.score(Xvaldata,yval)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_params = params\n",
    "            print(f\"Best score  for all variants in non-sklearn TreeClassifier: {best_score}\")\n",
    "            print(f\"Best params: {best_params}\")\n",
    "        else:\n",
    "            parameters = {\n",
    "                'max_depth': range(2,10),\n",
    "                'min_samples_split': [2, 3, 4,5],\n",
    "                'criterion': ['gini', 'entropy']\n",
    "            }\n",
    "            parameters_grid = ParameterGrid(parameters)\n",
    "            best_params = None\n",
    "            best_score = 0\n",
    "            for params in parameters_grid:\n",
    "                model = sklearn_DecisionTreeClassifier(**params)\n",
    "                model.fit(Xdata,ytrain)\n",
    "                score = model.score(Xvaldata,yval)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_params = params\n",
    "            print(f\"Best score  for all variants in sklearn TreeClassifier: {best_score}\")\n",
    "            print(f\"Best params: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1da11296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score  for all variants in sklearn KNN: 0.6637554585152838\n",
      "Best params: {'n_neighbors': 9, 'p': 2, 'weights': 'distance'}\n",
      "Best score  for all variants in sklearn KNN: 0.6506550218340611\n",
      "Best params: {'n_neighbors': 9, 'p': 2, 'weights': 'distance'}\n",
      "Best score  for all variants in non-sklearn KNN: 0.6200873362445415\n",
      "Best params: {'n_neighbors': 9, 'p': 2, 'task_class': 'c', 'weights': 'uniform'}\n",
      "Best score  for all variants in non-sklearn KNN: 0.5938864628820961\n",
      "Best params: {'n_neighbors': 9, 'p': 2, 'task_class': 'c', 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "model_tuning('KNN',Xtrain_standart,Xval_standart,True)\n",
    "model_tuning('KNN',Xtrain_normal,Xval_normal,True)\n",
    "model_tuning('KNN',Xtrain_standart,Xval_standart,False)\n",
    "model_tuning('KNN',Xtrain_normal,Xval_normal,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ecb477b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score  for all variants in sklearn LogisticRegression: 0.6375545851528385\n",
      "Best params: {'C': 1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "Best score  for all variants in sklearn LogisticRegression: 0.6375545851528385\n",
      "Best params: {'C': 100, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "Best score  for all variants in non-sklearn LogisticRegression: 0.5982532751091703\n",
      "Best params: {'fit_intercept': True, 'learning_rate': 0.005, 'n_iters': 200}\n",
      "Best score  for all variants in non-sklearn LogisticRegression: 0.47161572052401746\n",
      "Best params: {'fit_intercept': False, 'learning_rate': 0.01, 'n_iters': 300}\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "model_tuning('LogisticRegression',Xtrain_standart,Xval_standart,True)\n",
    "model_tuning('LogisticRegression',Xtrain_normal,Xval_normal,True)\n",
    "model_tuning('LogisticRegression',Xtrain_standart,Xval_standart,False)\n",
    "model_tuning('LogisticRegression',Xtrain_normal,Xval_normal,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cecd9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score  for all variants in sklearn TreeClassifier: 0.6200873362445415\n",
      "Best params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 4}\n",
      "Best score  for all variants in sklearn TreeClassifier: 0.6157205240174672\n",
      "Best params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 3}\n",
      "Best score  for all variants in non-sklearn TreeClassifier: 0.6200873362445415\n",
      "Best params: {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 4}\n",
      "Best score  for all variants in non-sklearn TreeClassifier: 0.6200873362445415\n",
      "Best params: {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 4}\n"
     ]
    }
   ],
   "source": [
    "model_tuning('ClassificationTree',Xtrain_standart,Xval_standart,True)\n",
    "model_tuning('ClassificationTree',Xtrain_normal,Xval_normal,True)\n",
    "model_tuning('ClassificationTree',Xtrain_standart,Xval_standart,False)\n",
    "model_tuning('ClassificationTree',Xtrain_normal,Xval_normal,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6708153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy (sklearn LogisticRegression): 0.5677 | Params: {'C': 1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "Final test accuracy (custom LogisticRegression): 0.5328 | Params: {'learning_rate': 0.01, 'n_iters': 200, 'fit_intercept': True}\n",
      "Final test accuracy (sklearn KNN): 0.6157 | Params: {'n_neighbors': 9, 'p': 2, 'weights': 'distance'}\n",
      "Final test accuracy (custom KNN): 0.5415 | Params: {'n_neighbors': 9, 'p': 2, 'weights': 'uniform', 'task_class': 'c'}\n",
      "Final test accuracy (sklearn TreeClassifier): 0.5459 | Params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 4}\n",
      "Final test accuracy (custom TreeClassifier): 0.5284 | Params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "best_params_sklearn_lr = {'C': 1, 'max_iter': 100, 'solver': 'lbfgs'}\n",
    "best_params_custom_lr = {'learning_rate': 0.01, 'n_iters': 200, 'fit_intercept': True}\n",
    "\n",
    "best_params_sklearn_knn = {'n_neighbors': 9, 'p': 2, 'weights': 'distance'}\n",
    "best_params_custom_knn = {'n_neighbors': 9, 'p': 2, 'weights': 'uniform', 'task_class': 'c'}\n",
    "\n",
    "best_params_sklearn_tree = {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 4}\n",
    "best_params_custom_tree = {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2}\n",
    "\n",
    "sklearn_lr = sklearn_LogisticRegression(**best_params_sklearn_lr)\n",
    "sklearn_lr.fit(Xtrain_standart, ytrain)\n",
    "sklearn_lr_test_score = sklearn_lr.score(Xtest_standart, ytest)\n",
    "\n",
    "custom_lr = LogisticRegression(**best_params_custom_lr)\n",
    "custom_lr.fit(Xtrain_standart, ytrain)\n",
    "custom_lr_test_score = custom_lr.score(Xtest_standart, ytest)\n",
    "\n",
    "print(f'Final test accuracy (sklearn LogisticRegression): {sklearn_lr_test_score:.4f} | Params: {best_params_sklearn_lr}')\n",
    "print(f'Final test accuracy (custom LogisticRegression): {custom_lr_test_score:.4f} | Params: {best_params_custom_lr}')\n",
    "\n",
    "sklearn_knn = sklearn_KNeighborsClassifier(**best_params_sklearn_knn)\n",
    "sklearn_knn.fit(Xtrain_standart, ytrain)\n",
    "sklearn_knn_test_score = sklearn_knn.score(Xtest_standart, ytest)\n",
    "\n",
    "custom_knn = KNN(**best_params_custom_knn)\n",
    "custom_knn.fit(Xtrain_standart, ytrain)\n",
    "custom_knn_test_score = custom_knn.score(Xtest_standart, ytest)\n",
    "\n",
    "print(f'Final test accuracy (sklearn KNN): {sklearn_knn_test_score:.4f} | Params: {best_params_sklearn_knn}')\n",
    "print(f'Final test accuracy (custom KNN): {custom_knn_test_score:.4f} | Params: {best_params_custom_knn}')\n",
    "\n",
    "sklearn_tree = sklearn_DecisionTreeClassifier(**best_params_sklearn_tree)\n",
    "sklearn_tree.fit(Xtrain_standart, ytrain)\n",
    "sklearn_tree_test_score = sklearn_tree.score(Xtest_standart, ytest)\n",
    "\n",
    "custom_tree = TreeClassifier(**best_params_custom_tree)\n",
    "custom_tree.fit(Xtrain_standart, ytrain)\n",
    "custom_tree_test_score = custom_tree.score(Xtest_standart, ytest)\n",
    "\n",
    "print(f'Final test accuracy (sklearn TreeClassifier): {sklearn_tree_test_score:.4f} | Params: {best_params_sklearn_tree}')\n",
    "print(f'Final test accuracy (custom TreeClassifier): {custom_tree_test_score:.4f} | Params: {best_params_custom_tree}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcea02f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "os.makedirs('../models/classification', exist_ok=True)\n",
    "\n",
    "joblib.dump(sklearn_lr, '../models/classification/sklearn_logistic_regression.joblib')\n",
    "print('Saved sklearn LogisticRegression to models/classification/sklearn_logistic_regression.joblib')\n",
    "\n",
    "joblib.dump(custom_lr, '../models/classification/custom_logistic_regression.joblib')\n",
    "print('Saved custom LogisticRegression to models/classification/custom_logistic_regression.joblib')\n",
    "\n",
    "joblib.dump(sklearn_knn, '../models/classification/sklearn_knn.joblib')\n",
    "print('Saved sklearn KNN to models/classification/sklearn_knn.joblib')\n",
    "\n",
    "joblib.dump(custom_knn, '../models/classification/custom_knn.joblib')\n",
    "print('Saved custom KNN to models/classification/custom_knn.joblib')\n",
    "\n",
    "joblib.dump(sklearn_tree, '../models/classification/sklearn_tree_classifier.joblib')\n",
    "print('Saved sklearn TreeClassifier to models/classification/sklearn_tree_classifier.joblib')\n",
    "\n",
    "\n",
    "joblib.dump(custom_tree, '../models/classification/custom_tree_classifier.joblib')\n",
    "print('Saved custom TreeClassifier to models/classification/custom_tree_classifier.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
